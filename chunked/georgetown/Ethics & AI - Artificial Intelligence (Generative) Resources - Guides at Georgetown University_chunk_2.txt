language model systems are trained to simply predict the most likely sequence of words in response to a given prompt, and will therefore reflect and perpetuate the biases inherent in the inputted internet information. An additional source of bias lies in the fact that some generative AI tools utilize reinforcement learning with human feedback (RLHF), with the caveat that the human testers used to provide this feedback are themselves non-neutral. Accordingly, generative AI like ChatGPT is documented to have provided output that is socio-politically biased, occasionally even containing sexist, racist, or otherwise offensive information. Related Recommendations Meticulously fact-check all of the information produced by generative AI, including verifying the source of all citations the AI uses to support its claims. Critically evaluate all AI output for any possible biases that can skew the presented information. Avoid asking the AI tools to produce a list of sources on a specific topic as such prompts may result in the tools fabricating false citations. When available, consult the AI developers' notes to determine if the tool's information is up-to-date. Always remember that generative AI tools are not search engines--they simply use large amounts of data to generate responses constructed to "make sense" according to common cognitive paradigms. Selected Readings Alkaissi, H., & McFarlane, S. I. (2023). Artificial hallucinations in ChatGPT: Implications in scientific writing. Curēus , 15 (2), e35179–e35179. https://doi.org/10.7759/cureus.35179 Bowman, E. (2022, December 19). A new AI chatbot might do your homework for you. But it's still not an A+ student . NPR. De Vynck, G. (2023, August 16). ChatGPT leans liberal, research shows . The Washington Post . Drahl, C. (2023, October 6). AI was asked to create images of Black African docs treating white kids. How'd it go? . NPR. Metz, C. (2021, March 15). Who is making sure the A.I. machines aren’t racist? New York Times [Digital Edition]. Walters, W. H., & Wilder, E. I. (2023). Fabrication and errors in the bibliographic citations generated by ChatGPT . Scientific Reports , 13 (1), 14045–14045. https://doi.org/10.1038/s41598-023-41032-5 Artificial Intelligence and Academic Integrity Plagiarism Generative AI tools have introduced new challenges in academic integrity, particularly related to plagiarism. Plagiarism is typically defined as presenting someone else's work or ideas as one's own . While a generative AI tool might not qualify as a "someone," using text generated from an AI tool without citing is still considered plagiarism, according to Georgetown University Honor Council , because the work is still not the researcher's own. Individual policies for using and crediting GAI tools might vary from class to class, so looking at the syllabus and having a clear understanding from the professor is important. A note about plagiarism detection tools : A number of AI detection tools are currently available to publishers and institutions, but there are concerns about low rates of accuracy and false accusations. Because generative AI tools do not generate large amounts of text word-for-word from existing works, it can be difficult for automated tools to detect plagiarism. Georgetown does not currently