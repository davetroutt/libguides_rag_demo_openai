detection tools are currently available to publishers and institutions, but there are concerns about low rates of accuracy and false accusations. Because generative AI tools do not generate large amounts of text word-for-word from existing works, it can be difficult for automated tools to detect plagiarism. Georgetown does not currently use the AI detection feature of its plagiarism detection tool, Turnitin. False Citations Another area of academic integrity affected by GAI tools is that of false citations. Providing false citations in research, whether intentional or unintentional, violates the Honor Council's Standards of Conduct . GAI tools such as ChatGPT have been known to generate false citations, and even if the citations represent actual papers, the cited content in ChatGPT might still be inaccurate. Related Recommendations If GAI tools are only permitted to be used for topic development, in the early stages of research, you might not need to cite them at all, but it's still important to check with your professor first. If you are providing commentary or analysis on the text generated by a chatbot and are either paraphrasing its results or quoting it directly, a citation is always required. You can find more information on citing GAI tools on this guide's Citing Generative AI page. If you are a researcher planning to publish in a journal, it is best to review that journal's policies on the permitted use of Generative AI tools. (See 'Selected Readings' below for a couple of examples of journal policies.) It's important to always look up citations and check to make sure they are accurate, and if you're citing information from that source, to cite the original source rather than ChatGPT or whichever GAI tool you're using. Selected Readings "Artificial intelligence: Editorial policies." (2023). Nature . Hoover, A. (2023, August 17). Use of AI Is Seeping Into Academic Journals—and It’s Proving Difficult to Detect . Wired . Liang, W., Yuksekgonul, M., Mao, Y., Wu, E., & Zou, J. (2023). GPT detectors are biased against non-native English writers. Patterns . " Science journals: Editorial policies - authorship." (2023) Science . Staiman, A. (2023, September 14). Publishers, Don’t Use AI Detection Tools! The Scholarly Kitchen. Privacy and AI Breaches of Privacy & Danger of Re-Identification There are currently also multiple privacy concerns associated with the use of generative AI tools. The most prominent issues revolve around the possibility of a breach of personal/sensitive data and re-identification . More specifically, most AI-powered language models, including ChatGPT, require for users to input large amounts of data to be trained and generate new information products effectively. This translates into personal or sensitive user-submitted data becoming an integral part of the collection of material used to further train the AI without the explicit consent of the user. Moreover, certain generative AI policies even permit AI developers to profit off of this personal/sensitive information by selling it to third parties. Even in cases when clear identifying personal information is not entered by AI user, the utilization of the system carries a